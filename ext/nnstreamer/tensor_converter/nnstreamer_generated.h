// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_NNSTREAMER_NNSTREAMER_H_
#define FLATBUFFERS_GENERATED_NNSTREAMER_NNSTREAMER_H_

#include "flatbuffers/flatbuffers.h"

namespace NNStreamer {

struct frame_rate;

struct Tensor;

struct Tensors;

enum Tensor_type {
  Tensor_type_NNS_INT32 = 0,
  Tensor_type_NNS_UINT32 = 1,
  Tensor_type_NNS_INT16 = 2,
  Tensor_type_NNS_UINT16 = 3,
  Tensor_type_NNS_INT8 = 4,
  Tensor_type_NNS_UINT8 = 5,
  Tensor_type_NNS_FLOAT64 = 6,
  Tensor_type_NNS_FLOAT32 = 7,
  Tensor_type_NNS_INT64 = 8,
  Tensor_type_NNS_UINT64 = 9,
  Tensor_type_NNS_END = 10,
  Tensor_type_MIN = Tensor_type_NNS_INT32,
  Tensor_type_MAX = Tensor_type_NNS_END
};

inline const Tensor_type (&EnumValuesTensor_type())[11] {
  static const Tensor_type values[] = {
    Tensor_type_NNS_INT32,
    Tensor_type_NNS_UINT32,
    Tensor_type_NNS_INT16,
    Tensor_type_NNS_UINT16,
    Tensor_type_NNS_INT8,
    Tensor_type_NNS_UINT8,
    Tensor_type_NNS_FLOAT64,
    Tensor_type_NNS_FLOAT32,
    Tensor_type_NNS_INT64,
    Tensor_type_NNS_UINT64,
    Tensor_type_NNS_END
  };
  return values;
}

inline const char * const *EnumNamesTensor_type() {
  static const char * const names[] = {
    "NNS_INT32",
    "NNS_UINT32",
    "NNS_INT16",
    "NNS_UINT16",
    "NNS_INT8",
    "NNS_UINT8",
    "NNS_FLOAT64",
    "NNS_FLOAT32",
    "NNS_INT64",
    "NNS_UINT64",
    "NNS_END",
    nullptr
  };
  return names;
}

inline const char *EnumNameTensor_type(Tensor_type e) {
  if (e < Tensor_type_NNS_INT32 || e > Tensor_type_NNS_END) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesTensor_type()[index];
}

FLATBUFFERS_MANUALLY_ALIGNED_STRUCT(4) frame_rate FLATBUFFERS_FINAL_CLASS {
 private:
  int32_t rate_n_;
  int32_t rate_d_;

 public:
  frame_rate() {
    memset(static_cast<void *>(this), 0, sizeof(frame_rate));
  }
  frame_rate(int32_t _rate_n, int32_t _rate_d)
      : rate_n_(flatbuffers::EndianScalar(_rate_n)),
        rate_d_(flatbuffers::EndianScalar(_rate_d)) {
  }
  int32_t rate_n() const {
    return flatbuffers::EndianScalar(rate_n_);
  }
  int32_t rate_d() const {
    return flatbuffers::EndianScalar(rate_d_);
  }
};
FLATBUFFERS_STRUCT_END(frame_rate, 8);

struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NAME = 4,
    VT_TYPE = 6,
    VT_DIMENSION = 8,
    VT_DATA = 10
  };
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  Tensor_type type() const {
    return static_cast<Tensor_type>(GetField<int32_t>(VT_TYPE, 10));
  }
  const flatbuffers::String *dimension() const {
    return GetPointer<const flatbuffers::String *>(VT_DIMENSION);
  }
  const flatbuffers::Vector<uint8_t> *data() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_DATA);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyField<int32_t>(verifier, VT_TYPE) &&
           VerifyOffset(verifier, VT_DIMENSION) &&
           verifier.VerifyString(dimension()) &&
           VerifyOffset(verifier, VT_DATA) &&
           verifier.VerifyVector(data()) &&
           verifier.EndTable();
  }
};

struct TensorBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Tensor::VT_NAME, name);
  }
  void add_type(Tensor_type type) {
    fbb_.AddElement<int32_t>(Tensor::VT_TYPE, static_cast<int32_t>(type), 10);
  }
  void add_dimension(flatbuffers::Offset<flatbuffers::String> dimension) {
    fbb_.AddOffset(Tensor::VT_DIMENSION, dimension);
  }
  void add_data(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> data) {
    fbb_.AddOffset(Tensor::VT_DATA, data);
  }
  explicit TensorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorBuilder &operator=(const TensorBuilder &);
  flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensor>(end);
    return o;
  }
};

inline flatbuffers::Offset<Tensor> CreateTensor(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    Tensor_type type = Tensor_type_NNS_END,
    flatbuffers::Offset<flatbuffers::String> dimension = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> data = 0) {
  TensorBuilder builder_(_fbb);
  builder_.add_data(data);
  builder_.add_dimension(dimension);
  builder_.add_type(type);
  builder_.add_name(name);
  return builder_.Finish();
}

inline flatbuffers::Offset<Tensor> CreateTensorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *name = nullptr,
    Tensor_type type = Tensor_type_NNS_END,
    const char *dimension = nullptr,
    const std::vector<uint8_t> *data = nullptr) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto dimension__ = dimension ? _fbb.CreateString(dimension) : 0;
  auto data__ = data ? _fbb.CreateVector<uint8_t>(*data) : 0;
  return NNStreamer::CreateTensor(
      _fbb,
      name__,
      type,
      dimension__,
      data__);
}

struct Tensors FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NUM_TENSOR = 4,
    VT_FR = 6,
    VT_TENSOR = 8
  };
  int32_t num_tensor() const {
    return GetField<int32_t>(VT_NUM_TENSOR, 0);
  }
  const frame_rate *fr() const {
    return GetStruct<const frame_rate *>(VT_FR);
  }
  const flatbuffers::Vector<flatbuffers::Offset<Tensor>> *tensor() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Tensor>> *>(VT_TENSOR);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_NUM_TENSOR) &&
           VerifyField<frame_rate>(verifier, VT_FR) &&
           VerifyOffset(verifier, VT_TENSOR) &&
           verifier.VerifyVector(tensor()) &&
           verifier.VerifyVectorOfTables(tensor()) &&
           verifier.EndTable();
  }
};

struct TensorsBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_num_tensor(int32_t num_tensor) {
    fbb_.AddElement<int32_t>(Tensors::VT_NUM_TENSOR, num_tensor, 0);
  }
  void add_fr(const frame_rate *fr) {
    fbb_.AddStruct(Tensors::VT_FR, fr);
  }
  void add_tensor(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Tensor>>> tensor) {
    fbb_.AddOffset(Tensors::VT_TENSOR, tensor);
  }
  explicit TensorsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorsBuilder &operator=(const TensorsBuilder &);
  flatbuffers::Offset<Tensors> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensors>(end);
    return o;
  }
};

inline flatbuffers::Offset<Tensors> CreateTensors(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t num_tensor = 0,
    const frame_rate *fr = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Tensor>>> tensor = 0) {
  TensorsBuilder builder_(_fbb);
  builder_.add_tensor(tensor);
  builder_.add_fr(fr);
  builder_.add_num_tensor(num_tensor);
  return builder_.Finish();
}

inline flatbuffers::Offset<Tensors> CreateTensorsDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t num_tensor = 0,
    const frame_rate *fr = 0,
    const std::vector<flatbuffers::Offset<Tensor>> *tensor = nullptr) {
  auto tensor__ = tensor ? _fbb.CreateVector<flatbuffers::Offset<Tensor>>(*tensor) : 0;
  return NNStreamer::CreateTensors(
      _fbb,
      num_tensor,
      fr,
      tensor__);
}

inline const NNStreamer::Tensors *GetTensors(const void *buf) {
  return flatbuffers::GetRoot<NNStreamer::Tensors>(buf);
}

inline const NNStreamer::Tensors *GetSizePrefixedTensors(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<NNStreamer::Tensors>(buf);
}

inline bool VerifyTensorsBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<NNStreamer::Tensors>(nullptr);
}

inline bool VerifySizePrefixedTensorsBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<NNStreamer::Tensors>(nullptr);
}

inline void FinishTensorsBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<NNStreamer::Tensors> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedTensorsBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<NNStreamer::Tensors> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace NNStreamer

#endif  // FLATBUFFERS_GENERATED_NNSTREAMER_NNSTREAMER_H_
